<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

### 19.5 LSTM的反向传播

和RNN一样，LSTM也采用基于时间的反向传播算法（Backpropagation Through Time, BPTT）。LSTM的误差项也是沿两个方向传播：
1. 沿时间的反向传播
2. 向上一层网络的反向传播

上一节中介绍了LSTM前向计算的过程，重新列出如下：
$$
f_t = \sigma(W_{fh}h_{t-1}+W_{fx}x_t+b_f) \tag{公式 1}
$$
$$
i_t=\sigma(W_i\cdot[h_{t-1}, x_t] + b_i) \tag{公式 2}
$$
$$
\tilde{c}_t=tanh(W_c\cdot[h_{t-1}, x_t] + b_c) \tag{公式 3}
$$
$$
c_t=f_t \circ c_{t-1}+i_t \circ \tilde{c}_t \tag{公式 4}
$$
$$
o_t=\sigma(W_o\cdot[h_{t-1}, x_t] + b_o) \tag{公式 5}
$$
$$
h_t=o_t \circ tanh(c_t) \tag{公式 6}
$$
$$
\hat{y} = \sigma(Vh_t + c) \tag{公式 7}
$$

LSTM网络的损失函数 $L$ 可以用均方差损失函数：
$$
L_t = \frac12(\hat{y_t}-y_t)^2 \\
L = \sum_{t=1}^{\tau}L_t
$$

或交叉熵损失函数：
$$
L_t = -y_t\log\hat{y_t} \\
L = \sum_tL_t = -\sum_t{y_t\log\hat{y_t}}
$$

下面开始推导反向传播的过程。

#### 19.5.1 误差项沿时间的反向传播

#### 19.5.2 误差项向上一层的反向传播
